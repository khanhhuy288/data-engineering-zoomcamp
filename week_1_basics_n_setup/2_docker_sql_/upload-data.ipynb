{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c0f57bc-8e7f-4458-aa01-9b8f9d9585e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c22ac355-e597-4daa-893a-aee872236e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3da1de39-e320-4baa-9bf2-590b136500c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('yellow_tripdata_2021-01.csv', nrows=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "173940e4-7750-420c-aba1-40546032f32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tpep_pickup_datetime = pd.to_datetime(df.tpep_pickup_datetime)\n",
    "df.tpep_dropoff_datetime = pd.to_datetime(df.tpep_dropoff_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c5d0f65-c1a6-413e-a3c1-952ce27ae45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afdd1c95-37d7-471d-9d93-25ddd106c631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE yellow_taxi_data (\n",
      "\t\"VendorID\" BIGINT, \n",
      "\ttpep_pickup_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
      "\ttpep_dropoff_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
      "\tpassenger_count BIGINT, \n",
      "\ttrip_distance FLOAT(53), \n",
      "\t\"RatecodeID\" BIGINT, \n",
      "\tstore_and_fwd_flag TEXT, \n",
      "\t\"PULocationID\" BIGINT, \n",
      "\t\"DOLocationID\" BIGINT, \n",
      "\tpayment_type BIGINT, \n",
      "\tfare_amount FLOAT(53), \n",
      "\textra FLOAT(53), \n",
      "\tmta_tax FLOAT(53), \n",
      "\ttip_amount FLOAT(53), \n",
      "\ttolls_amount FLOAT(53), \n",
      "\timprovement_surcharge FLOAT(53), \n",
      "\ttotal_amount FLOAT(53), \n",
      "\tcongestion_surcharge FLOAT(53)\n",
      ")\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.io.sql.get_schema(df, name='yellow_taxi_data', con=engine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5d7fb714-7fdb-4084-b1c8-a919daca9653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted another chunk... took 6.243 seconds.\n",
      "Inserted another chunk... took 6.525 seconds.\n",
      "Inserted another chunk... took 6.392 seconds.\n",
      "Inserted another chunk... took 6.777 seconds.\n",
      "Inserted another chunk... took 7.033 seconds.\n",
      "Inserted another chunk... took 6.888 seconds.\n",
      "Inserted another chunk... took 7.201 seconds.\n",
      "Inserted another chunk... took 7.030 seconds.\n",
      "Inserted another chunk... took 6.859 seconds.\n",
      "Inserted another chunk... took 6.837 seconds.\n",
      "Inserted another chunk... took 6.758 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vs/_r7c0zhs07g_2l34drz17qgh0000gn/T/ipykernel_37961/687269206.py:14: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in df_iter:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted another chunk... took 6.732 seconds.\n",
      "Inserted another chunk... took 4.486 seconds.\n"
     ]
    }
   ],
   "source": [
    "df_iter = pd.read_csv('yellow_tripdata_2021-01.csv', iterator=True, chunksize=100000)\n",
    "\n",
    "# Get the first chunk\n",
    "df = next(df_iter)\n",
    "\n",
    "# Convert datetime columns\n",
    "df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])\n",
    "df['tpep_dropoff_datetime'] = pd.to_datetime(df['tpep_dropoff_datetime'])\n",
    "\n",
    "# Write the first chunk to SQL and replace existing data\n",
    "df.to_sql(name='yellow_taxi_data', con=engine, if_exists='replace')\n",
    "\n",
    "# Iterate over remaining chunks\n",
    "for chunk in df_iter:\n",
    "    t_start = time()\n",
    "\n",
    "    # Convert datetime columns\n",
    "    chunk['tpep_pickup_datetime'] = pd.to_datetime(chunk['tpep_pickup_datetime'])\n",
    "    chunk['tpep_dropoff_datetime'] = pd.to_datetime(chunk['tpep_dropoff_datetime'])\n",
    "\n",
    "    # Write chunk to SQL and append to existing data\n",
    "    chunk.to_sql(name='yellow_taxi_data', con=engine, if_exists='append')\n",
    "\n",
    "    t_end = time()\n",
    "    print(f'Inserted another chunk... took {t_end-t_start:.3f} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03079b7e-591c-41f0-ac9f-2ca58d687c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-01-31 12:00:10--  https://s3.amazonaws.com/nyc-tlc/misc/taxi+_zone_lookup.csv\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.48.30, 54.231.199.120, 54.231.196.88, ...\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.48.30|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12322 (12K) [application/octet-stream]\n",
      "Saving to: ‘taxi+_zone_lookup.csv.1’\n",
      "\n",
      "taxi+_zone_lookup.c 100%[===================>]  12,03K  --.-KB/s    in 0,001s  \n",
      "\n",
      "2023-01-31 12:00:11 (21,5 MB/s) - ‘taxi+_zone_lookup.csv.1’ saved [12322/12322]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the zone data\n",
    "!wget https://s3.amazonaws.com/nyc-tlc/misc/taxi+_zone_lookup.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e5e4efb-c124-4f11-a913-0b94b7e28f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zones = pd.read_csv('taxi+_zone_lookup.csv')\n",
    "df_zones.to_sql(name='zones', con=engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9a1a438-6a16-4360-b4c2-e336f8b78e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-01-31 12:10:26--  https://github.com/DataTalksClub/nyc-tlc-data/releases/download/green/green_tripdata_2019-01.csv.gz\n",
      "Resolving github.com (github.com)... 140.82.121.4\n",
      "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/d3904232-1a2b-431b-803d-0ee802cd14fc?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230131%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230131T111026Z&X-Amz-Expires=300&X-Amz-Signature=06d2225ce72d002b56fc818d34c31de86e55b0f4180bc1da21a485ad52ef6690&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dgreen_tripdata_2019-01.csv.gz&response-content-type=application%2Foctet-stream [following]\n",
      "--2023-01-31 12:10:26--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/d3904232-1a2b-431b-803d-0ee802cd14fc?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230131%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230131T111026Z&X-Amz-Expires=300&X-Amz-Signature=06d2225ce72d002b56fc818d34c31de86e55b0f4180bc1da21a485ad52ef6690&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dgreen_tripdata_2019-01.csv.gz&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 11099245 (11M) [application/octet-stream]\n",
      "Saving to: ‘green_tripdata_2019-01.csv.gz’\n",
      "\n",
      "green_tripdata_2019 100%[===================>]  10,58M  5,04MB/s    in 2,1s    \n",
      "\n",
      "2023-01-31 12:10:29 (5,04 MB/s) - ‘green_tripdata_2019-01.csv.gz’ saved [11099245/11099245]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/green/green_tripdata_2019-01.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e60ae10-f370-4481-a3be-2d6cf6bb6ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load green taxi trips\n",
    "csv_name = 'green_tripdata_2019-01.csv.gz'\n",
    "table_name = 'green_taxi_trips'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e454fcd6-74d3-424d-9c86-8657d482ab55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iter = pd.read_csv(csv_name, iterator=True, chunksize=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5e989ac-4448-494e-9ed5-dd8f9ca0aff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = next(df_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8188edf-f91b-4d3c-8044-b4f6b3b59066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>lpep_pickup_datetime</th>\n",
       "      <th>lpep_dropoff_datetime</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>ehail_fee</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>trip_type</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-12-21 15:17:29</td>\n",
       "      <td>2018-12-21 15:18:57</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>264</td>\n",
       "      <td>264</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-01 00:10:16</td>\n",
       "      <td>2019-01-01 00:16:32</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>0.86</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-01 00:27:11</td>\n",
       "      <td>2019-01-01 00:31:38</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>189</td>\n",
       "      <td>2</td>\n",
       "      <td>0.66</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-01 00:46:20</td>\n",
       "      <td>2019-01-01 01:04:54</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>2.68</td>\n",
       "      <td>13.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>19.71</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-01 00:19:06</td>\n",
       "      <td>2019-01-01 00:39:43</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>258</td>\n",
       "      <td>1</td>\n",
       "      <td>4.53</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>19.30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID lpep_pickup_datetime lpep_dropoff_datetime store_and_fwd_flag  \\\n",
       "0         2  2018-12-21 15:17:29   2018-12-21 15:18:57                  N   \n",
       "1         2  2019-01-01 00:10:16   2019-01-01 00:16:32                  N   \n",
       "2         2  2019-01-01 00:27:11   2019-01-01 00:31:38                  N   \n",
       "3         2  2019-01-01 00:46:20   2019-01-01 01:04:54                  N   \n",
       "4         2  2019-01-01 00:19:06   2019-01-01 00:39:43                  N   \n",
       "\n",
       "   RatecodeID  PULocationID  DOLocationID  passenger_count  trip_distance  \\\n",
       "0           1           264           264                5           0.00   \n",
       "1           1            97            49                2           0.86   \n",
       "2           1            49           189                2           0.66   \n",
       "3           1           189            17                2           2.68   \n",
       "4           1            82           258                1           4.53   \n",
       "\n",
       "   fare_amount  extra  mta_tax  tip_amount  tolls_amount  ehail_fee  \\\n",
       "0          3.0    0.5      0.5        0.00           0.0        NaN   \n",
       "1          6.0    0.5      0.5        0.00           0.0        NaN   \n",
       "2          4.5    0.5      0.5        0.00           0.0        NaN   \n",
       "3         13.5    0.5      0.5        2.96           0.0        NaN   \n",
       "4         18.0    0.5      0.5        0.00           0.0        NaN   \n",
       "\n",
       "   improvement_surcharge  total_amount  payment_type  trip_type  \\\n",
       "0                    0.3          4.30             2          1   \n",
       "1                    0.3          7.30             2          1   \n",
       "2                    0.3          5.80             1          1   \n",
       "3                    0.3         19.71             1          1   \n",
       "4                    0.3         19.30             2          1   \n",
       "\n",
       "   congestion_surcharge  \n",
       "0                   NaN  \n",
       "1                   NaN  \n",
       "2                   NaN  \n",
       "3                   NaN  \n",
       "4                   NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84b9a912-7bc5-4360-a8af-47831d19c1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert datetime columns\n",
    "df['lpep_pickup_datetime'] = pd.to_datetime(df['lpep_pickup_datetime'])\n",
    "df['lpep_dropoff_datetime'] = pd.to_datetime(df['lpep_dropoff_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c39b9f9-dbd5-4847-93ba-278acee80b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write the first chunk to SQL and replace existing data\n",
    "df.to_sql(name=table_name, con=engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3937eb84-180e-4dc8-946e-ad84a9cc659c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted another chunk... took 6.693 seconds.\n",
      "Inserted another chunk... took 6.727 seconds.\n",
      "Inserted another chunk... took 6.706 seconds.\n",
      "Inserted another chunk... took 6.687 seconds.\n",
      "Inserted another chunk... took 6.790 seconds.\n",
      "Inserted another chunk... took 2.203 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Iterate over remaining chunks\n",
    "for chunk in df_iter:\n",
    "    t_start = time()\n",
    "\n",
    "    # Convert datetime columns\n",
    "    chunk['lpep_pickup_datetime'] = pd.to_datetime(chunk['lpep_pickup_datetime'])\n",
    "    chunk['lpep_dropoff_datetime'] = pd.to_datetime(chunk['lpep_dropoff_datetime'])\n",
    "\n",
    "    # Write chunk to SQL and append to existing data\n",
    "    chunk.to_sql(name=table_name, con=engine, if_exists='append')\n",
    "\n",
    "    t_end = time()\n",
    "    print(f'Inserted another chunk... took {t_end - t_start:.3f} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c8c486-eef0-434e-b9e7-ae5b1f033b56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
